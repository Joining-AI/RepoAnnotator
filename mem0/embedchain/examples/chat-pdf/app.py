# å¯¼å…¥éœ€è¦çš„åº“ï¼Œå°±åƒæ˜¯å‡†å¤‡ç”»ç”»å‰æŒ‘é€‰å¥½é¢œæ–™å’Œç”»ç¬”
import os
import queue
import re
import tempfile
import threading

import streamlit as st

from embedchain import App
from embedchain.config import BaseLlmConfig
from embedchain.helpers.callbacks import (StreamingStdOutCallbackHandlerYield,
                                          generate)

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨æ¥åˆ›å»ºä¸€ä¸ªèŠå¤©æœºå™¨äººï¼Œéœ€è¦ä¼ å…¥æ•°æ®åº“è·¯å¾„å’ŒAPIå¯†é’¥
def embedchain_bot(db_path, api_key):
    # ä½¿ç”¨ä¼ å…¥çš„é…ç½®ä¿¡æ¯æ¥åˆå§‹åŒ–ä¸€ä¸ªèŠå¤©æœºå™¨äºº
    return App.from_config(
        # é…ç½®ä¿¡æ¯ï¼Œå‘Šè¯‰æœºå™¨äººå¦‚ä½•å·¥ä½œ
        config={
            # LLMï¼ˆè¯­è¨€æ¨¡å‹ï¼‰çš„è®¾ç½®ï¼Œè¿™é‡Œç”¨çš„æ˜¯OpenAIçš„GPT-3.5æ¨¡å‹
            "llm": {
                "provider": "openai",  # ä½¿ç”¨OpenAIä½œä¸ºè¯­è¨€æ¨¡å‹çš„æä¾›è€…
                "config": {
                    "model": "gpt-3.5-turbo-1106",  # æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬
                    "temperature": 0.5,  # æ§åˆ¶å›ç­”çš„éšæœºæ€§
                    "max_tokens": 1000,  # æœ€å¤§å›ç­”é•¿åº¦
                    "top_p": 1,  # æ§åˆ¶å›ç­”çš„å¤šæ ·æ€§
                    "stream": True,  # æ˜¯å¦æµå¼ä¼ è¾“å›ç­”
                    "api_key": api_key,  # OpenAIçš„APIå¯†é’¥
                },
            },
            # å‘é‡æ•°æ®åº“çš„è®¾ç½®ï¼Œç”¨äºå­˜å‚¨å’Œæ£€ç´¢ä¿¡æ¯
            "vectordb": {
                "provider": "chroma",  # ä½¿ç”¨Chromaä½œä¸ºå‘é‡æ•°æ®åº“
                "config": {
                    "collection_name": "chat-pdf",  # æ•°æ®é›†åç§°
                    "dir": db_path,  # æ•°æ®åº“è·¯å¾„
                    "allow_reset": True,  # å…è®¸é‡ç½®æ•°æ®åº“
                },
            },
            # åµŒå…¥å™¨çš„è®¾ç½®ï¼Œç”¨äºå°†æ–‡æœ¬è½¬æ¢æˆå‘é‡
            "embedder": {"provider": "openai", "config": {"api_key": api_key}},  # ä½¿ç”¨OpenAIçš„åµŒå…¥å™¨
            # åˆ†å—å™¨çš„è®¾ç½®ï¼Œç”¨äºå°†é•¿æ–‡æœ¬åˆ†å‰²æˆå°å—
            "chunker": {"chunk_size": 2000, "chunk_overlap": 0, "length_function": "len"},  # åˆ†å—å¤§å°ã€é‡å éƒ¨åˆ†ã€é•¿åº¦è®¡ç®—æ–¹å¼
        }
    )

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨æ¥è·å–æ•°æ®åº“çš„ä¸´æ—¶è·¯å¾„
def get_db_path():
    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶ç›®å½•
    tmpdirname = tempfile.mkdtemp()
    # è¿”å›è¿™ä¸ªä¸´æ—¶ç›®å½•çš„è·¯å¾„
    return tmpdirname

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨æ¥è·å–æˆ–åˆ›å»ºèŠå¤©æœºå™¨äººå®ä¾‹
def get_ec_app(api_key):
    # å¦‚æœsession_stateä¸­å·²ç»æœ‰èŠå¤©æœºå™¨äººå®ä¾‹äº†
    if "app" in st.session_state:
        print("æ‰¾åˆ°äº†session_stateä¸­çš„èŠå¤©æœºå™¨äºº")  # æ‰“å°ä¸€æ¡æ¶ˆæ¯
        app = st.session_state.app  # ç›´æ¥ä»session_stateä¸­è·å–
    else:  # å¦‚æœsession_stateä¸­æ²¡æœ‰èŠå¤©æœºå™¨äººå®ä¾‹
        print("æ­£åœ¨åˆ›å»ºæ–°çš„èŠå¤©æœºå™¨äºº")  # æ‰“å°ä¸€æ¡æ¶ˆæ¯
        # è°ƒç”¨get_db_path()å‡½æ•°è·å–æ•°æ®åº“è·¯å¾„
        db_path = get_db_path()
        # è°ƒç”¨embedchain_bot()å‡½æ•°åˆ›å»ºèŠå¤©æœºå™¨äººå®ä¾‹
        app = embedchain_bot(db_path, api_key)
        # å°†æ–°åˆ›å»ºçš„èŠå¤©æœºå™¨äººå®ä¾‹å­˜å…¥session_state
        st.session_state.app = app
    # è¿”å›èŠå¤©æœºå™¨äººå®ä¾‹
    return app

# è¿™é‡Œæ˜¯åœ¨ä¾§è¾¹æ é‡Œåšçš„ä¸€äº›äº‹æƒ…
with st.sidebar:
    # è¿™è¡Œä»£ç è®©ç”¨æˆ·è¾“å…¥ä»–ä»¬çš„OpenAI APIå¯†é’¥ï¼Œå¹¶ä¿å­˜åœ¨ä¸€ä¸ªå«åšopenai_access_tokençš„å˜é‡ä¸­ã€‚
    # ç”¨æˆ·è¾“å…¥çš„ä¿¡æ¯ä¼šè¢«éšè—èµ·æ¥ï¼Œå› ä¸ºç±»å‹è®¾ç½®ä¸º"å¯†ç "ã€‚
    openai_access_token = st.text_input("OpenAI API Key", key="api_key", type="password")
    # è¿™ä¸¤è¡Œå‘Šè¯‰ç”¨æˆ·æˆ‘ä»¬ä¸ä¼šä¿å­˜ä»–ä»¬çš„APIå¯†é’¥ï¼Œå¹¶å‘Šè¯‰ä»–ä»¬å¦‚ä½•è·å–APIå¯†é’¥ã€‚
    "WE DO NOT STORE YOUR OPENAI KEY."
    "Just paste your OpenAI API key here and we'll use it to power the chatbot. [Get your OpenAI API key](https://platform.openai.com/api-keys)"  # noqa: E501

    # å¦‚æœç”¨æˆ·å·²ç»è¾“å…¥äº†APIå¯†é’¥å¹¶ä¿å­˜åœ¨session_stateé‡Œï¼Œé‚£ä¹ˆå°±ç”¨è¿™ä¸ªå¯†é’¥åˆ›å»ºä¸€ä¸ªåº”ç”¨å®ä¾‹ã€‚
    if st.session_state.api_key:
        app = get_ec_app(st.session_state.api_key)

# è®©ç”¨æˆ·ä¸Šä¼ PDFæ–‡ä»¶
pdf_files = st.file_uploader("Upload your PDF files", accept_multiple_files=True, type="pdf")
# è·å–ä¹‹å‰æ·»åŠ è¿‡çš„PDFæ–‡ä»¶ååˆ—è¡¨
add_pdf_files = st.session_state.get("add_pdf_files", [])

# éå†ç”¨æˆ·ä¸Šä¼ çš„æ‰€æœ‰PDFæ–‡ä»¶
for pdf_file in pdf_files:
    # è·å–æ–‡ä»¶å
    file_name = pdf_file.name
    # å¦‚æœè¿™ä¸ªæ–‡ä»¶å·²ç»è¢«æ·»åŠ è¿‡äº†ï¼Œå°±ä¸éœ€è¦å†æ¬¡å¤„ç†
    if file_name in add_pdf_files:
        continue
    try:
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²ç»è¾“å…¥äº†APIå¯†é’¥
        if not st.session_state.api_key:
            # å¦‚æœæ²¡æœ‰è¾“å…¥å¯†é’¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯å¹¶åœæ­¢ç¨‹åºæ‰§è¡Œ
            st.error("Please enter your OpenAI API Key")
            st.stop()
        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ–‡ä»¶ï¼Œç”¨äºå­˜å‚¨ä¸Šä¼ çš„PDFæ–‡ä»¶
        temp_file_name = None
        with tempfile.NamedTemporaryFile(mode="wb", delete=False, prefix=file_name, suffix=".pdf") as f:
            # æŠŠPDFæ–‡ä»¶å†…å®¹å†™å…¥ä¸´æ—¶æ–‡ä»¶
            f.write(pdf_file.getvalue())
            temp_file_name = f.name
        # å¦‚æœä¸´æ—¶æ–‡ä»¶åˆ›å»ºæˆåŠŸ
        if temp_file_name:
            # æ˜¾ç¤ºæ­£åœ¨æŠŠæ–‡ä»¶åŠ å…¥çŸ¥è¯†åº“çš„æ¶ˆæ¯
            st.markdown(f"Adding {file_name} to knowledge base...")
            # æŠŠä¸´æ—¶æ–‡ä»¶æ·»åŠ åˆ°åº”ç”¨çš„çŸ¥è¯†åº“ä¸­
            app.add(temp_file_name, data_type="pdf_file")
            # æ¸…ç©ºä¸€ä¸‹æ˜¾ç¤ºåŒºåŸŸ
            st.markdown("")
            # æŠŠæ–‡ä»¶åæ·»åŠ åˆ°å·²å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨ä¸­
            add_pdf_files.append(file_name)
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            os.remove(temp_file_name)
        # æ˜¾ç¤ºæ–‡ä»¶å·²æˆåŠŸæ·»åŠ åˆ°çŸ¥è¯†åº“çš„æ¶ˆæ¯
        st.session_state.messages.append({"role": "assistant", "content": f"Added {file_name} to knowledge base!"})
    # å¦‚æœå‡ºç°å¼‚å¸¸ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯å¹¶åœæ­¢ç¨‹åºæ‰§è¡Œ
    except Exception as e:
        st.error(f"Error adding {file_name} to knowledge base: {e}")
        st.stop()
# æ›´æ–°å·²å¤„ç†çš„PDFæ–‡ä»¶åˆ—è¡¨
st.session_state["add_pdf_files"] = add_pdf_files

# è®¾ç½®ç½‘é¡µæ ‡é¢˜
st.title("ğŸ“„ Embedchain - Chat with PDF")
# è®¾ç½®ä¸€ä¸ªå¥½çœ‹çš„ä»‹ç»æ–‡å­—
styled_caption = '<p style="font-size: 17px; color: #aaa;">ğŸš€ An <a href="https://github.com/embedchain/embedchain">Embedchain</a> app powered by OpenAI!</p>'  # noqa: E501
st.markdown(styled_caption, unsafe_allow_html=True)

# å¦‚æœmessagesè¿˜æ²¡æœ‰åœ¨session_stateä¸­ï¼Œå°±åˆå§‹åŒ–å®ƒ
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": """
                Hi! I'm chatbot powered by Embedchain, which can answer questions about your pdf documents.\n
                Upload your pdf documents here and I'll answer your questions about them! 
            """,
        }
    ]

# éå†æ¶ˆæ¯åˆ—è¡¨å¹¶æ˜¾ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# å¦‚æœç”¨æˆ·è¾“å…¥äº†ä¸€ä¸ªé—®é¢˜
if prompt := st.chat_input("Ask me anything!"):
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²ç»è¾“å…¥äº†APIå¯†é’¥
    if not st.session_state.api_key:
        # å¦‚æœæ²¡æœ‰è¾“å…¥å¯†é’¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯å¹¶åœæ­¢ç¨‹åºæ‰§è¡Œ
        st.error("Please enter your OpenAI API Key", icon="ğŸ¤–")
        st.stop()

    # ä½¿ç”¨ç”¨æˆ·çš„APIå¯†é’¥åˆ›å»ºä¸€ä¸ªåº”ç”¨å®ä¾‹
    app = get_ec_app(st.session_state.api_key)

    # æ˜¾ç¤ºç”¨æˆ·çš„é—®é¢˜
    with st.chat_message("user"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.markdown(prompt)

    # æ˜¾ç¤ºæœºå™¨äººçš„å›ç­”
    with st.chat_message("assistant"):
        # å…ˆé¢„ç•™ä¸€ä¸ªä½ç½®æ˜¾ç¤ºæœºå™¨äººæ­£åœ¨æ€è€ƒ
        msg_placeholder = st.empty()
        msg_placeholder.markdown("Thinking...")
        # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„å›ç­”
        full_response = ""

        # å®šä¹‰ä¸€ä¸ªé˜Ÿåˆ—ï¼Œç”¨äºæ¥æ”¶å›ç­”çš„ç‰‡æ®µ
        q = queue.Queue()

        # å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œè®©åº”ç”¨ç”Ÿæˆå›ç­”å’Œå¼•ç”¨æ¥æº
        def app_response(result):
            # è·å¾—é…ç½®ä¿¡æ¯
            llm_config = app.llm.config.as_dict()
            # è®¾ç½®å›è°ƒå‡½æ•°ï¼Œç”¨äºè·å–å®æ—¶çš„å›ç­”ç‰‡æ®µ
            llm_config["callbacks"] = [StreamingStdOutCallbackHandlerYield(q=q)]
            config = BaseLlmConfig(**llm_config)
            # è·å–å›ç­”å’Œå¼•ç”¨æ¥æº
            answer, citations = app.chat(prompt, config=config, citations=True)
            # æŠŠç»“æœä¿å­˜åˆ°å­—å…¸ä¸­
            result["answer"] = answer
            result["citations"] = citations

        # åˆ›å»ºä¸€ä¸ªå­—å…¸æ¥ä¿å­˜ç»“æœ
        results = {}
        # åˆ›å»ºä¸€ä¸ªçº¿ç¨‹æ¥å¼‚æ­¥è·å–å›ç­”
        thread = threading.Thread(target=app_response, args=(results,))
        thread.start()

        # ä»é˜Ÿåˆ—ä¸­è·å–å›ç­”çš„ç‰‡æ®µï¼Œå¹¶é€æ­¥æ˜¾ç¤º
        for answer_chunk in generate(q):
            full_response += answer_chunk
            msg_placeholder.markdown(full_response)

        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        thread.join()
        # ä»ç»“æœå­—å…¸ä¸­è·å–æœ€ç»ˆçš„å›ç­”å’Œå¼•ç”¨æ¥æº
        answer, citations = results["answer"], results["citations"]
        # å¦‚æœæœ‰å¼•ç”¨æ¥æºï¼Œå°±åŠ ä¸Šæ¥æºä¿¡æ¯
        if citations:
            full_response += "\n\n**Sources**:\n"
            sources = []
            for i, citation in enumerate(citations):
                source = citation[1]["url"]
                # ä»URLä¸­æå–æ–‡ä»¶å
                pattern = re.compile(r"([^/]+)\.[^\.]+\.pdf$")
                match = pattern.search(source)
                if match:
                    source = match.group(1) + ".pdf"
                sources.append(source)
            # å»é™¤é‡å¤çš„æ–‡ä»¶å
            sources = list(set(sources))
            # æ˜¾ç¤ºæ‰€æœ‰æ¥æºçš„æ–‡ä»¶å
            for source in sources:
                full_response += f"- {source}\n"

        # æ˜¾ç¤ºæœ€ç»ˆçš„å›ç­”
        msg_placeholder.markdown(full_response)
        # æ‰“å°å›ç­”ï¼Œæ–¹ä¾¿å¼€å‘è€…æŸ¥çœ‹
        print("Answer: ", full_response)
        # æŠŠå›ç­”ä¿å­˜åˆ°session_stateä¸­
        st.session_state.messages.append({"role": "assistant", "content": full_response})

